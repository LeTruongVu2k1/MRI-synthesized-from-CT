
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 23, 'patch_size': [256, 192], 'median_image_size_in_voxels': [251.5, 186.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Liver', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [30, 252, 186], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0, 'mean': 0.2606104910373688, 'median': 0.24769647419452667, 'min': 0.0, 'percentile_00_5': 0.06384892016649246, 'percentile_99_5': 0.6531020402908325, 'std': 0.0987810268998146}}} 
 
2023-05-02 10:16:03.473696: unpacking dataset... 
2023-05-02 10:16:03.687589: unpacking done... 
2023-05-02 10:16:03.689918: do_dummy_2d_data_aug: False 
2023-05-02 10:16:03.696374: Using splits from existing split file: drive/MyDrive/nnUNet/nnUNet_preprocessed/Dataset001_Liver/splits_final.json 
2023-05-02 10:16:03.699355: The split file contains 5 splits. 
2023-05-02 10:16:03.701056: Desired fold for training: 0 
2023-05-02 10:16:03.703251: This split has 12 training and 4 validation cases. 
2023-05-02 10:16:03.734771: Unable to plot network architecture: 
2023-05-02 10:16:03.736583: No module named 'hiddenlayer' 
2023-05-02 10:16:03.752138:  
2023-05-02 10:16:03.754137: Epoch 24 
2023-05-02 10:16:03.756750: Current learning rate: 0.00781 
2023-05-02 10:18:29.950794: train_loss -0.9574 
2023-05-02 10:18:29.965729: val_loss -0.8336 
2023-05-02 10:18:29.970111: Pseudo dice [0.9087] 
2023-05-02 10:18:29.973452: Epoch time: 146.2 s 
2023-05-02 10:18:29.976914: Yayy! New best EMA pseudo Dice: 0.9053 
2023-05-02 10:18:34.572167:  
2023-05-02 10:18:34.574549: Epoch 25 
2023-05-02 10:18:34.577566: Current learning rate: 0.00772 
2023-05-02 10:20:49.714021: train_loss -0.9549 
2023-05-02 10:20:49.718123: val_loss -0.8592 
2023-05-02 10:20:49.722161: Pseudo dice [0.9276] 
2023-05-02 10:20:49.726128: Epoch time: 135.14 s 
2023-05-02 10:20:49.729067: Yayy! New best EMA pseudo Dice: 0.9076 
2023-05-02 10:20:53.866743:  
2023-05-02 10:20:53.869593: Epoch 26 
2023-05-02 10:20:53.872311: Current learning rate: 0.00763 
2023-05-02 10:23:08.802210: train_loss -0.958 
2023-05-02 10:23:08.804601: val_loss -0.8478 
2023-05-02 10:23:08.807668: Pseudo dice [0.9222] 
2023-05-02 10:23:08.810844: Epoch time: 134.94 s 
2023-05-02 10:23:08.812306: Yayy! New best EMA pseudo Dice: 0.909 
2023-05-02 10:23:12.243662:  
2023-05-02 10:23:12.246073: Epoch 27 
2023-05-02 10:23:12.249485: Current learning rate: 0.00753 
2023-05-02 10:25:27.056222: train_loss -0.959 
2023-05-02 10:25:27.061447: val_loss -0.8541 
2023-05-02 10:25:27.064600: Pseudo dice [0.9251] 
2023-05-02 10:25:27.069140: Epoch time: 134.81 s 
2023-05-02 10:25:27.074258: Yayy! New best EMA pseudo Dice: 0.9106 
2023-05-02 10:25:30.369079:  
2023-05-02 10:25:30.371944: Epoch 28 
2023-05-02 10:25:30.374792: Current learning rate: 0.00744 
2023-05-02 10:27:44.755685: train_loss -0.9605 
2023-05-02 10:27:44.760423: val_loss -0.8121 
2023-05-02 10:27:44.763986: Pseudo dice [0.9085] 
2023-05-02 10:27:44.768196: Epoch time: 134.39 s 
2023-05-02 10:27:48.255517:  
2023-05-02 10:27:48.258342: Epoch 29 
2023-05-02 10:27:48.260839: Current learning rate: 0.00735 
2023-05-02 10:30:03.738100: train_loss -0.9621 
2023-05-02 10:30:03.745596: val_loss -0.8505 
2023-05-02 10:30:03.749928: Pseudo dice [0.9215] 
2023-05-02 10:30:03.753618: Epoch time: 135.48 s 
2023-05-02 10:30:04.947334: Yayy! New best EMA pseudo Dice: 0.9115 
2023-05-02 10:30:07.912301:  
2023-05-02 10:30:07.914856: Epoch 30 
2023-05-02 10:30:07.918146: Current learning rate: 0.00725 
2023-05-02 10:32:23.307552: train_loss -0.9629 
2023-05-02 10:32:23.311735: val_loss -0.8372 
2023-05-02 10:32:23.315315: Pseudo dice [0.9181] 
2023-05-02 10:32:23.318388: Epoch time: 135.4 s 
2023-05-02 10:32:23.321643: Yayy! New best EMA pseudo Dice: 0.9122 
2023-05-02 10:32:26.326542:  
2023-05-02 10:32:26.328947: Epoch 31 
2023-05-02 10:32:26.331917: Current learning rate: 0.00716 
2023-05-02 10:34:41.362762: train_loss -0.9649 
2023-05-02 10:34:41.374088: val_loss -0.8435 
2023-05-02 10:34:41.378324: Pseudo dice [0.9222] 
2023-05-02 10:34:41.382502: Epoch time: 135.04 s 
2023-05-02 10:34:41.385550: Yayy! New best EMA pseudo Dice: 0.9132 
2023-05-02 10:34:45.312176:  
2023-05-02 10:34:45.315125: Epoch 32 
2023-05-02 10:34:45.317634: Current learning rate: 0.00707 
2023-05-02 10:37:00.295625: train_loss -0.9654 
2023-05-02 10:37:00.310302: val_loss -0.8527 
2023-05-02 10:37:00.314821: Pseudo dice [0.9257] 
2023-05-02 10:37:00.318424: Epoch time: 134.99 s 
2023-05-02 10:37:00.322801: Yayy! New best EMA pseudo Dice: 0.9144 
2023-05-02 10:37:04.019773:  
2023-05-02 10:37:04.022426: Epoch 33 
2023-05-02 10:37:04.025157: Current learning rate: 0.00697 
2023-05-02 10:39:18.956288: train_loss -0.967 
2023-05-02 10:39:18.960223: val_loss -0.8112 
2023-05-02 10:39:18.963418: Pseudo dice [0.9074] 
2023-05-02 10:39:18.967433: Epoch time: 134.94 s 
2023-05-02 10:39:21.614463:  
2023-05-02 10:39:21.616751: Epoch 34 
2023-05-02 10:39:21.620718: Current learning rate: 0.00688 
2023-05-02 10:41:36.980368: train_loss -0.9666 
2023-05-02 10:41:36.990919: val_loss -0.8459 
2023-05-02 10:41:36.994461: Pseudo dice [0.9243] 
2023-05-02 10:41:36.998012: Epoch time: 135.37 s 
2023-05-02 10:41:37.001871: Yayy! New best EMA pseudo Dice: 0.9148 
2023-05-02 10:41:40.039541:  
2023-05-02 10:41:40.042070: Epoch 35 
2023-05-02 10:41:40.050619: Current learning rate: 0.00679 
2023-05-02 10:43:55.794060: train_loss -0.9662 
2023-05-02 10:43:55.799963: val_loss -0.8463 
2023-05-02 10:43:55.804019: Pseudo dice [0.9244] 
2023-05-02 10:43:55.808273: Epoch time: 135.76 s 
2023-05-02 10:43:55.814917: Yayy! New best EMA pseudo Dice: 0.9158 
2023-05-02 10:43:59.945787:  
2023-05-02 10:43:59.947908: Epoch 36 
2023-05-02 10:43:59.960458: Current learning rate: 0.00669 
2023-05-02 10:46:14.910882: train_loss -0.9672 
2023-05-02 10:46:14.914121: val_loss -0.8295 
2023-05-02 10:46:14.918602: Pseudo dice [0.9168] 
2023-05-02 10:46:14.921629: Epoch time: 134.97 s 
2023-05-02 10:46:14.925322: Yayy! New best EMA pseudo Dice: 0.9159 
2023-05-02 10:46:17.943845:  
2023-05-02 10:46:17.946368: Epoch 37 
2023-05-02 10:46:17.949039: Current learning rate: 0.0066 
2023-05-02 10:48:32.406335: train_loss -0.9687 
2023-05-02 10:48:32.410141: val_loss -0.853 
2023-05-02 10:48:32.413411: Pseudo dice [0.9264] 
2023-05-02 10:48:32.416612: Epoch time: 134.46 s 
2023-05-02 10:48:32.420603: Yayy! New best EMA pseudo Dice: 0.9169 
2023-05-02 10:48:35.431433:  
2023-05-02 10:48:35.433673: Epoch 38 
2023-05-02 10:48:35.436573: Current learning rate: 0.0065 
2023-05-02 10:50:52.775365: train_loss -0.9689 
2023-05-02 10:50:52.780759: val_loss -0.8209 
2023-05-02 10:50:52.785509: Pseudo dice [0.9103] 
2023-05-02 10:50:52.790612: Epoch time: 137.34 s 
2023-05-02 10:50:55.627822:  
2023-05-02 10:50:55.631568: Epoch 39 
2023-05-02 10:50:55.634655: Current learning rate: 0.00641 
2023-05-02 10:53:09.166881: train_loss -0.9697 
2023-05-02 10:53:09.172393: val_loss -0.8473 
2023-05-02 10:53:09.176372: Pseudo dice [0.9232] 
2023-05-02 10:53:09.179380: Epoch time: 133.54 s 
2023-05-02 10:53:09.866627: Yayy! New best EMA pseudo Dice: 0.917 
2023-05-02 10:53:13.038938:  
2023-05-02 10:53:13.041716: Epoch 40 
2023-05-02 10:53:13.044719: Current learning rate: 0.00631 
2023-05-02 10:55:28.555577: train_loss -0.9703 
2023-05-02 10:55:28.559104: val_loss -0.8565 
2023-05-02 10:55:28.562448: Pseudo dice [0.9264] 
2023-05-02 10:55:28.566736: Epoch time: 135.52 s 
2023-05-02 10:55:28.570535: Yayy! New best EMA pseudo Dice: 0.9179 
2023-05-02 10:55:31.681698:  
2023-05-02 10:55:31.684251: Epoch 41 
2023-05-02 10:55:31.687137: Current learning rate: 0.00622 
2023-05-02 10:57:48.448609: train_loss -0.9713 
2023-05-02 10:57:48.454587: val_loss -0.862 
2023-05-02 10:57:48.464657: Pseudo dice [0.9306] 
2023-05-02 10:57:48.467950: Epoch time: 136.77 s 
2023-05-02 10:57:48.472449: Yayy! New best EMA pseudo Dice: 0.9192 
2023-05-02 10:57:52.589592:  
2023-05-02 10:57:52.591612: Epoch 42 
2023-05-02 10:57:52.594285: Current learning rate: 0.00612 
2023-05-02 11:00:06.596218: train_loss -0.9716 
2023-05-02 11:00:06.599908: val_loss -0.8635 
2023-05-02 11:00:06.604543: Pseudo dice [0.9323] 
2023-05-02 11:00:06.607725: Epoch time: 134.01 s 
2023-05-02 11:00:06.611576: Yayy! New best EMA pseudo Dice: 0.9205 
2023-05-02 11:00:09.636668:  
2023-05-02 11:00:09.639220: Epoch 43 
2023-05-02 11:00:09.641831: Current learning rate: 0.00603 
2023-05-02 11:02:23.104467: train_loss -0.9723 
2023-05-02 11:02:23.107992: val_loss -0.8603 
2023-05-02 11:02:23.111129: Pseudo dice [0.9292] 
2023-05-02 11:02:23.116513: Epoch time: 133.47 s 
2023-05-02 11:02:23.119371: Yayy! New best EMA pseudo Dice: 0.9213 
2023-05-02 11:02:26.081521:  
2023-05-02 11:02:26.084045: Epoch 44 
2023-05-02 11:02:26.086896: Current learning rate: 0.00593 
2023-05-02 11:04:40.664685: train_loss -0.9716 
2023-05-02 11:04:40.668201: val_loss -0.844 
2023-05-02 11:04:40.671916: Pseudo dice [0.9214] 
2023-05-02 11:04:40.676747: Epoch time: 134.58 s 
2023-05-02 11:04:40.680041: Yayy! New best EMA pseudo Dice: 0.9213 
2023-05-02 11:04:44.362337:  
2023-05-02 11:04:44.365323: Epoch 45 
2023-05-02 11:04:44.367623: Current learning rate: 0.00584 
2023-05-02 11:06:59.900923: train_loss -0.9725 
2023-05-02 11:06:59.908200: val_loss -0.8408 
2023-05-02 11:06:59.914858: Pseudo dice [0.9223] 
2023-05-02 11:06:59.918680: Epoch time: 135.54 s 
2023-05-02 11:06:59.923886: Yayy! New best EMA pseudo Dice: 0.9214 
2023-05-02 11:07:03.609705:  
2023-05-02 11:07:03.612659: Epoch 46 
2023-05-02 11:07:03.615665: Current learning rate: 0.00574 
2023-05-02 11:09:17.605331: train_loss -0.9722 
2023-05-02 11:09:17.610098: val_loss -0.8292 
2023-05-02 11:09:17.613502: Pseudo dice [0.9163] 
2023-05-02 11:09:17.616622: Epoch time: 134.0 s 
2023-05-02 11:09:20.044454:  
2023-05-02 11:09:20.047304: Epoch 47 
2023-05-02 11:09:20.050973: Current learning rate: 0.00565 
2023-05-02 11:11:34.320262: train_loss -0.9732 
2023-05-02 11:11:34.323898: val_loss -0.834 
2023-05-02 11:11:34.327489: Pseudo dice [0.9211] 
2023-05-02 11:11:34.330637: Epoch time: 134.28 s 
2023-05-02 11:11:36.724878:  
2023-05-02 11:11:36.728244: Epoch 48 
2023-05-02 11:11:36.730614: Current learning rate: 0.00555 
2023-05-02 11:13:51.289459: train_loss -0.9732 
2023-05-02 11:13:51.294277: val_loss -0.8347 
2023-05-02 11:13:51.297635: Pseudo dice [0.9224] 
2023-05-02 11:13:51.300900: Epoch time: 134.57 s 
2023-05-02 11:13:54.591399:  
2023-05-02 11:13:54.594198: Epoch 49 
2023-05-02 11:13:54.596933: Current learning rate: 0.00546 
2023-05-02 11:16:08.819990: train_loss -0.9718 
2023-05-02 11:16:08.826820: val_loss -0.8534 
2023-05-02 11:16:08.831390: Pseudo dice [0.9299] 
2023-05-02 11:16:08.835589: Epoch time: 134.23 s 
2023-05-02 11:16:09.943757: Yayy! New best EMA pseudo Dice: 0.922 
2023-05-02 11:16:13.029907:  
2023-05-02 11:16:13.032202: Epoch 50 
2023-05-02 11:16:13.035196: Current learning rate: 0.00536 
2023-05-02 11:18:26.914653: train_loss -0.9732 
2023-05-02 11:18:26.918155: val_loss -0.8522 
2023-05-02 11:18:26.921529: Pseudo dice [0.9248] 
2023-05-02 11:18:26.925595: Epoch time: 133.89 s 
2023-05-02 11:18:26.930094: Yayy! New best EMA pseudo Dice: 0.9223 
2023-05-02 11:18:29.964358:  
2023-05-02 11:18:29.966773: Epoch 51 
2023-05-02 11:18:29.969415: Current learning rate: 0.00526 
2023-05-02 11:20:44.479577: train_loss -0.9735 
2023-05-02 11:20:44.483915: val_loss -0.8512 
2023-05-02 11:20:44.487739: Pseudo dice [0.9253] 
2023-05-02 11:20:44.491863: Epoch time: 134.52 s 
2023-05-02 11:20:44.494974: Yayy! New best EMA pseudo Dice: 0.9226 
2023-05-02 11:20:47.857538:  
2023-05-02 11:20:47.859866: Epoch 52 
2023-05-02 11:20:47.864749: Current learning rate: 0.00517 
2023-05-02 11:23:02.886840: train_loss -0.9746 
2023-05-02 11:23:02.905385: val_loss -0.8506 
2023-05-02 11:23:02.911666: Pseudo dice [0.9258] 
2023-05-02 11:23:02.916482: Epoch time: 135.03 s 
2023-05-02 11:23:02.921161: Yayy! New best EMA pseudo Dice: 0.9229 
2023-05-02 11:23:06.820101:  
2023-05-02 11:23:06.822372: Epoch 53 
2023-05-02 11:23:06.825887: Current learning rate: 0.00507 
2023-05-02 11:25:20.343051: train_loss -0.9749 
2023-05-02 11:25:20.351460: val_loss -0.8354 
2023-05-02 11:25:20.355566: Pseudo dice [0.9192] 
2023-05-02 11:25:20.358410: Epoch time: 133.52 s 
2023-05-02 11:25:22.835801:  
2023-05-02 11:25:22.837921: Epoch 54 
2023-05-02 11:25:22.840768: Current learning rate: 0.00497 
2023-05-02 11:27:36.122873: train_loss -0.9746 
2023-05-02 11:27:36.126742: val_loss -0.8453 
2023-05-02 11:27:36.129990: Pseudo dice [0.9243] 
2023-05-02 11:27:36.133447: Epoch time: 133.29 s 
2023-05-02 11:27:38.571823:  
2023-05-02 11:27:38.574239: Epoch 55 
2023-05-02 11:27:38.579113: Current learning rate: 0.00487 
2023-05-02 11:29:51.589097: train_loss -0.9749 
2023-05-02 11:29:51.593622: val_loss -0.8544 
2023-05-02 11:29:51.597368: Pseudo dice [0.9291] 
2023-05-02 11:29:51.600732: Epoch time: 133.02 s 
2023-05-02 11:29:51.604767: Yayy! New best EMA pseudo Dice: 0.9233 
2023-05-02 11:29:54.641033:  
2023-05-02 11:29:54.643139: Epoch 56 
2023-05-02 11:29:54.646109: Current learning rate: 0.00478 
2023-05-02 11:32:09.961134: train_loss -0.9758 
2023-05-02 11:32:09.964291: val_loss -0.8566 
2023-05-02 11:32:09.967730: Pseudo dice [0.929] 
2023-05-02 11:32:09.971171: Epoch time: 135.32 s 
2023-05-02 11:32:09.974110: Yayy! New best EMA pseudo Dice: 0.9239 
2023-05-02 11:32:14.979580:  
2023-05-02 11:32:14.981882: Epoch 57 
2023-05-02 11:32:14.984716: Current learning rate: 0.00468 
2023-05-02 11:34:29.502910: train_loss -0.9759 
2023-05-02 11:34:29.509401: val_loss -0.8636 
2023-05-02 11:34:29.512990: Pseudo dice [0.9305] 
2023-05-02 11:34:29.516446: Epoch time: 134.52 s 
2023-05-02 11:34:29.519351: Yayy! New best EMA pseudo Dice: 0.9246 
2023-05-02 11:34:32.499219:  
2023-05-02 11:34:32.501613: Epoch 58 
2023-05-02 11:34:32.504339: Current learning rate: 0.00458 
2023-05-02 11:36:47.134569: train_loss -0.9754 
2023-05-02 11:36:47.138756: val_loss -0.8621 
2023-05-02 11:36:47.142376: Pseudo dice [0.9316] 
2023-05-02 11:36:47.145646: Epoch time: 134.64 s 
2023-05-02 11:36:47.148918: Yayy! New best EMA pseudo Dice: 0.9253 
2023-05-02 11:36:50.664262:  
2023-05-02 11:36:50.667975: Epoch 59 
2023-05-02 11:36:50.674298: Current learning rate: 0.00448 
2023-05-02 11:39:07.362075: train_loss -0.9756 
2023-05-02 11:39:07.371691: val_loss -0.8474 
2023-05-02 11:39:07.376622: Pseudo dice [0.9252] 
2023-05-02 11:39:07.389755: Epoch time: 136.7 s 
2023-05-02 11:39:10.702424:  
2023-05-02 11:39:10.704887: Epoch 60 
2023-05-02 11:39:10.708199: Current learning rate: 0.00438 
2023-05-02 11:41:25.684962: train_loss -0.9761 
2023-05-02 11:41:25.692418: val_loss -0.8459 
2023-05-02 11:41:25.696177: Pseudo dice [0.9256] 
2023-05-02 11:41:25.700118: Epoch time: 134.98 s 
2023-05-02 11:41:25.703558: Yayy! New best EMA pseudo Dice: 0.9253 
2023-05-02 11:41:28.761315:  
2023-05-02 11:41:28.763574: Epoch 61 
2023-05-02 11:41:28.766468: Current learning rate: 0.00429 
2023-05-02 11:43:43.097483: train_loss -0.9763 
2023-05-02 11:43:43.101265: val_loss -0.8598 
2023-05-02 11:43:43.104876: Pseudo dice [0.9298] 
2023-05-02 11:43:43.107852: Epoch time: 134.34 s 
2023-05-02 11:43:43.112417: Yayy! New best EMA pseudo Dice: 0.9257 
2023-05-02 11:43:46.735898:  
2023-05-02 11:43:46.738585: Epoch 62 
2023-05-02 11:43:46.741316: Current learning rate: 0.00419 
2023-05-02 11:46:02.826634: train_loss -0.9767 
2023-05-02 11:46:02.842163: val_loss -0.8302 
2023-05-02 11:46:02.852135: Pseudo dice [0.921] 
2023-05-02 11:46:02.857774: Epoch time: 136.09 s 
2023-05-02 11:46:06.248742:  
2023-05-02 11:46:06.251222: Epoch 63 
2023-05-02 11:46:06.254088: Current learning rate: 0.00409 
2023-05-02 11:48:21.728589: train_loss -0.9771 
2023-05-02 11:48:21.732027: val_loss -0.8505 
2023-05-02 11:48:21.736600: Pseudo dice [0.9288] 
2023-05-02 11:48:21.740222: Epoch time: 135.48 s 
2023-05-02 11:48:24.226638:  
2023-05-02 11:48:24.229617: Epoch 64 
2023-05-02 11:48:24.232180: Current learning rate: 0.00399 
2023-05-02 11:50:39.294469: train_loss -0.9772 
2023-05-02 11:50:39.297916: val_loss -0.852 
2023-05-02 11:50:39.301027: Pseudo dice [0.9306] 
2023-05-02 11:50:39.314757: Epoch time: 135.07 s 
2023-05-02 11:50:39.322671: Yayy! New best EMA pseudo Dice: 0.9261 
2023-05-02 11:50:43.015503:  
2023-05-02 11:50:43.018358: Epoch 65 
2023-05-02 11:50:43.020941: Current learning rate: 0.00389 
2023-05-02 11:52:56.659178: train_loss -0.9779 
2023-05-02 11:52:56.670566: val_loss -0.8493 
2023-05-02 11:52:56.675393: Pseudo dice [0.9275] 
2023-05-02 11:52:56.679567: Epoch time: 133.65 s 
2023-05-02 11:52:56.683786: Yayy! New best EMA pseudo Dice: 0.9263 
2023-05-02 11:53:01.062560:  
2023-05-02 11:53:01.066514: Epoch 66 
2023-05-02 11:53:01.069274: Current learning rate: 0.00379 
2023-05-02 11:55:15.011703: train_loss -0.9774 
2023-05-02 11:55:15.016113: val_loss -0.8535 
2023-05-02 11:55:15.019134: Pseudo dice [0.9299] 
2023-05-02 11:55:15.022431: Epoch time: 133.95 s 
2023-05-02 11:55:15.033982: Yayy! New best EMA pseudo Dice: 0.9266 
2023-05-02 11:55:18.107318:  
2023-05-02 11:55:18.109989: Epoch 67 
2023-05-02 11:55:18.112620: Current learning rate: 0.00369 
2023-05-02 11:57:32.093608: train_loss -0.9781 
2023-05-02 11:57:32.100107: val_loss -0.8358 
2023-05-02 11:57:32.103173: Pseudo dice [0.9225] 
2023-05-02 11:57:32.106753: Epoch time: 133.99 s 
2023-05-02 11:57:34.631132:  
2023-05-02 11:57:34.633316: Epoch 68 
2023-05-02 11:57:34.636267: Current learning rate: 0.00359 
2023-05-02 11:59:47.613563: train_loss -0.9779 
2023-05-02 11:59:47.617311: val_loss -0.8516 
2023-05-02 11:59:47.620666: Pseudo dice [0.9274] 
2023-05-02 11:59:47.625990: Epoch time: 132.98 s 
2023-05-02 11:59:50.790898:  
2023-05-02 11:59:50.793562: Epoch 69 
2023-05-02 11:59:50.796514: Current learning rate: 0.00349 
2023-05-02 12:02:05.320374: train_loss -0.9782 
2023-05-02 12:02:05.328641: val_loss -0.861 
2023-05-02 12:02:05.333129: Pseudo dice [0.9322] 
2023-05-02 12:02:05.346552: Epoch time: 134.53 s 
2023-05-02 12:02:06.417399: Yayy! New best EMA pseudo Dice: 0.9269 
2023-05-02 12:02:09.696863:  
2023-05-02 12:02:09.699097: Epoch 70 
2023-05-02 12:02:09.702018: Current learning rate: 0.00338 
2023-05-02 12:04:23.949464: train_loss -0.9779 
2023-05-02 12:04:23.952459: val_loss -0.8376 
2023-05-02 12:04:23.957200: Pseudo dice [0.9217] 
2023-05-02 12:04:23.961564: Epoch time: 134.25 s 
2023-05-02 12:04:26.411209:  
2023-05-02 12:04:26.413271: Epoch 71 
2023-05-02 12:04:26.416298: Current learning rate: 0.00328 
2023-05-02 12:06:39.327454: train_loss -0.9784 
2023-05-02 12:06:39.332863: val_loss -0.8544 
2023-05-02 12:06:39.335692: Pseudo dice [0.9297] 
2023-05-02 12:06:39.339619: Epoch time: 132.92 s 
2023-05-02 12:06:41.795848:  
2023-05-02 12:06:41.798159: Epoch 72 
2023-05-02 12:06:41.811418: Current learning rate: 0.00318 
2023-05-02 12:08:54.812776: train_loss -0.9792 
2023-05-02 12:08:54.816987: val_loss -0.8459 
2023-05-02 12:08:54.820589: Pseudo dice [0.9265] 
2023-05-02 12:08:54.823775: Epoch time: 133.02 s 
2023-05-02 12:08:57.364264:  
2023-05-02 12:08:57.366353: Epoch 73 
2023-05-02 12:08:57.370362: Current learning rate: 0.00308 
2023-05-02 12:11:10.834399: train_loss -0.9789 
2023-05-02 12:11:10.838655: val_loss -0.8446 
2023-05-02 12:11:10.842443: Pseudo dice [0.9258] 
2023-05-02 12:11:10.846203: Epoch time: 133.47 s 
2023-05-02 12:11:14.840920:  
2023-05-02 12:11:14.843699: Epoch 74 
2023-05-02 12:11:14.846126: Current learning rate: 0.00297 
2023-05-02 12:13:26.085918: train_loss -0.9792 
2023-05-02 12:13:26.094833: val_loss -0.8554 
2023-05-02 12:13:26.099602: Pseudo dice [0.929] 
2023-05-02 12:13:26.103398: Epoch time: 131.25 s 
2023-05-02 12:13:30.144728:  
2023-05-02 12:13:30.147112: Epoch 75 
2023-05-02 12:13:30.149874: Current learning rate: 0.00287 
