
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 23, 'patch_size': [256, 192], 'median_image_size_in_voxels': [251.5, 186.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Liver', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [30, 252, 186], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0, 'mean': 0.2606104910373688, 'median': 0.24769647419452667, 'min': 0.0, 'percentile_00_5': 0.06384892016649246, 'percentile_99_5': 0.6531020402908325, 'std': 0.0987810268998146}}} 
 
2023-05-01 08:56:18.008476: unpacking dataset... 
2023-05-01 08:56:18.232881: unpacking done... 
2023-05-01 08:56:18.238343: do_dummy_2d_data_aug: False 
2023-05-01 08:56:18.244623: Using splits from existing split file: drive/MyDrive/nnUNet/nnUNet_preprocessed/Dataset001_Liver/splits_final.json 
2023-05-01 08:56:18.247579: The split file contains 5 splits. 
2023-05-01 08:56:18.249203: Desired fold for training: 1 
2023-05-01 08:56:18.251126: This split has 13 training and 3 validation cases. 
2023-05-01 08:56:18.281617: Unable to plot network architecture: 
2023-05-01 08:56:18.283197: No module named 'hiddenlayer' 
2023-05-01 08:56:18.293003:  
2023-05-01 08:56:18.294718: Epoch 0 
2023-05-01 08:56:18.297211: Current learning rate: 0.01 
2023-05-01 08:58:43.319990: train_loss -0.4069 
2023-05-01 08:58:43.325602: val_loss -0.7865 
2023-05-01 08:58:43.329009: Pseudo dice [0.8765] 
2023-05-01 08:58:43.332369: Epoch time: 145.03 s 
2023-05-01 08:58:43.336015: Yayy! New best EMA pseudo Dice: 0.8765 
2023-05-01 08:58:46.077033:  
2023-05-01 08:58:46.080305: Epoch 1 
2023-05-01 08:58:46.082829: Current learning rate: 0.00955 
2023-05-01 09:00:59.188367: train_loss -0.7852 
2023-05-01 09:00:59.192792: val_loss -0.8517 
2023-05-01 09:00:59.196547: Pseudo dice [0.9199] 
2023-05-01 09:00:59.199644: Epoch time: 133.11 s 
2023-05-01 09:00:59.204117: Yayy! New best EMA pseudo Dice: 0.8808 
2023-05-01 09:01:02.092521:  
2023-05-01 09:01:02.095538: Epoch 2 
2023-05-01 09:01:02.098715: Current learning rate: 0.0091 
2023-05-01 09:03:17.693516: train_loss -0.8548 
2023-05-01 09:03:17.698298: val_loss -0.8465 
2023-05-01 09:03:17.700734: Pseudo dice [0.9155] 
2023-05-01 09:03:17.716779: Epoch time: 135.6 s 
2023-05-01 09:03:18.358984: Yayy! New best EMA pseudo Dice: 0.8843 
2023-05-01 09:03:22.258612:  
2023-05-01 09:03:22.261378: Epoch 3 
2023-05-01 09:03:22.263829: Current learning rate: 0.00864 
2023-05-01 09:05:37.406719: train_loss -0.8775 
2023-05-01 09:05:37.412411: val_loss -0.8807 
2023-05-01 09:05:37.416790: Pseudo dice [0.9361] 
2023-05-01 09:05:37.421874: Epoch time: 135.15 s 
2023-05-01 09:05:37.425824: Yayy! New best EMA pseudo Dice: 0.8895 
2023-05-01 09:05:42.038124:  
2023-05-01 09:05:42.042270: Epoch 4 
2023-05-01 09:05:42.045194: Current learning rate: 0.00818 
2023-05-01 09:07:56.731909: train_loss -0.9031 
2023-05-01 09:07:56.735354: val_loss -0.8674 
2023-05-01 09:07:56.739885: Pseudo dice [0.9274] 
2023-05-01 09:07:56.744047: Epoch time: 134.7 s 
2023-05-01 09:07:56.747105: Yayy! New best EMA pseudo Dice: 0.8933 
2023-05-01 09:07:59.743487:  
2023-05-01 09:07:59.745829: Epoch 5 
2023-05-01 09:07:59.748387: Current learning rate: 0.00772 
2023-05-01 09:10:15.029925: train_loss -0.9166 
2023-05-01 09:10:15.033684: val_loss -0.8913 
2023-05-01 09:10:15.037093: Pseudo dice [0.9423] 
2023-05-01 09:10:15.041747: Epoch time: 135.29 s 
2023-05-01 09:10:15.754175: Yayy! New best EMA pseudo Dice: 0.8982 
2023-05-01 09:10:18.489743:  
2023-05-01 09:10:18.492406: Epoch 6 
2023-05-01 09:10:18.495332: Current learning rate: 0.00725 
2023-05-01 09:12:34.237998: train_loss -0.9204 
2023-05-01 09:12:34.248265: val_loss -0.8822 
2023-05-01 09:12:34.253093: Pseudo dice [0.9368] 
2023-05-01 09:12:34.257234: Epoch time: 135.75 s 
2023-05-01 09:12:34.261032: Yayy! New best EMA pseudo Dice: 0.902 
2023-05-01 09:12:38.442796:  
2023-05-01 09:12:38.600788: Epoch 7 
2023-05-01 09:12:38.603632: Current learning rate: 0.00679 
2023-05-01 09:14:52.074222: train_loss -0.9307 
2023-05-01 09:14:52.080338: val_loss -0.8942 
2023-05-01 09:14:52.084527: Pseudo dice [0.9429] 
2023-05-01 09:14:52.089060: Epoch time: 133.63 s 
2023-05-01 09:14:52.095588: Yayy! New best EMA pseudo Dice: 0.9061 
2023-05-01 09:14:55.284990:  
2023-05-01 09:14:55.287344: Epoch 8 
2023-05-01 09:14:55.290219: Current learning rate: 0.00631 
2023-05-01 09:17:08.793031: train_loss -0.9362 
2023-05-01 09:17:08.805164: val_loss -0.9124 
2023-05-01 09:17:08.808697: Pseudo dice [0.9522] 
2023-05-01 09:17:08.811780: Epoch time: 133.51 s 
2023-05-01 09:17:09.453117: Yayy! New best EMA pseudo Dice: 0.9107 
2023-05-01 09:17:12.441603:  
2023-05-01 09:17:12.443785: Epoch 9 
2023-05-01 09:17:12.446455: Current learning rate: 0.00584 
2023-05-01 09:19:24.758911: train_loss -0.9405 
2023-05-01 09:19:24.762454: val_loss -0.8953 
2023-05-01 09:19:24.765697: Pseudo dice [0.9428] 
2023-05-01 09:19:24.769923: Epoch time: 132.32 s 
2023-05-01 09:19:24.773258: Yayy! New best EMA pseudo Dice: 0.9139 
2023-05-01 09:19:27.904203:  
2023-05-01 09:19:27.906821: Epoch 10 
2023-05-01 09:19:27.909202: Current learning rate: 0.00536 
2023-05-01 09:21:40.956096: train_loss -0.9442 
2023-05-01 09:21:40.959764: val_loss -0.8998 
2023-05-01 09:21:40.963118: Pseudo dice [0.9476] 
2023-05-01 09:21:40.967446: Epoch time: 133.05 s 
2023-05-01 09:21:40.970200: Yayy! New best EMA pseudo Dice: 0.9173 
2023-05-01 09:21:45.581201:  
2023-05-01 09:21:45.584011: Epoch 11 
2023-05-01 09:21:45.586703: Current learning rate: 0.00487 
2023-05-01 09:23:58.871567: train_loss -0.9475 
2023-05-01 09:23:58.881787: val_loss -0.8961 
2023-05-01 09:23:58.885852: Pseudo dice [0.9463] 
2023-05-01 09:23:58.900423: Epoch time: 133.29 s 
2023-05-01 09:23:59.771057: Yayy! New best EMA pseudo Dice: 0.9202 
2023-05-01 09:24:02.624227:  
2023-05-01 09:24:02.626587: Epoch 12 
2023-05-01 09:24:02.629305: Current learning rate: 0.00438 
2023-05-01 09:26:13.981417: train_loss -0.9481 
2023-05-01 09:26:13.984843: val_loss -0.9061 
2023-05-01 09:26:13.988697: Pseudo dice [0.9512] 
2023-05-01 09:26:13.992547: Epoch time: 131.36 s 
2023-05-01 09:26:13.996973: Yayy! New best EMA pseudo Dice: 0.9233 
2023-05-01 09:26:16.832441:  
2023-05-01 09:26:16.834536: Epoch 13 
2023-05-01 09:26:16.837252: Current learning rate: 0.00389 
2023-05-01 09:28:31.377064: train_loss -0.951 
2023-05-01 09:28:31.380971: val_loss -0.8851 
2023-05-01 09:28:31.384295: Pseudo dice [0.9455] 
2023-05-01 09:28:31.387530: Epoch time: 134.55 s 
2023-05-01 09:28:31.392138: Yayy! New best EMA pseudo Dice: 0.9255 
2023-05-01 09:28:34.376704:  
2023-05-01 09:28:34.378777: Epoch 14 
2023-05-01 09:28:34.381634: Current learning rate: 0.00338 
2023-05-01 09:30:45.398279: train_loss -0.9519 
2023-05-01 09:30:45.402328: val_loss -0.8933 
2023-05-01 09:30:45.406293: Pseudo dice [0.9461] 
2023-05-01 09:30:45.409538: Epoch time: 131.02 s 
2023-05-01 09:30:46.098803: Yayy! New best EMA pseudo Dice: 0.9276 
2023-05-01 09:30:50.919323:  
2023-05-01 09:30:50.922150: Epoch 15 
2023-05-01 09:30:50.924842: Current learning rate: 0.00287 
2023-05-01 09:33:04.790801: train_loss -0.9535 
2023-05-01 09:33:04.794188: val_loss -0.893 
2023-05-01 09:33:04.797643: Pseudo dice [0.9454] 
2023-05-01 09:33:04.802483: Epoch time: 133.87 s 
2023-05-01 09:33:04.805852: Yayy! New best EMA pseudo Dice: 0.9294 
2023-05-01 09:33:07.831157:  
2023-05-01 09:33:07.833403: Epoch 16 
2023-05-01 09:33:07.836182: Current learning rate: 0.00235 
