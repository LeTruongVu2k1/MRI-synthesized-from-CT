
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 23, 'patch_size': [256, 192], 'median_image_size_in_voxels': [251.5, 186.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Liver', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [30, 252, 186], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0, 'mean': 0.2606104910373688, 'median': 0.24769647419452667, 'min': 0.0, 'percentile_00_5': 0.06384892016649246, 'percentile_99_5': 0.6531020402908325, 'std': 0.0987810268998146}}} 
 
2023-05-02 14:01:19.405057: unpacking dataset... 
2023-05-02 14:02:05.234357: unpacking done... 
2023-05-02 14:02:06.837147: do_dummy_2d_data_aug: False 
2023-05-02 14:02:09.719886: Using splits from existing split file: drive/MyDrive/nnUNet/nnUNet_preprocessed/Dataset001_Liver/splits_final.json 
2023-05-02 14:02:11.446602: The split file contains 5 splits. 
2023-05-02 14:02:12.917515: Desired fold for training: 3 
2023-05-02 14:02:15.526123: This split has 13 training and 3 validation cases. 
2023-05-02 14:02:45.235959: Unable to plot network architecture: 
2023-05-02 14:02:46.464530: No module named 'hiddenlayer' 
2023-05-02 14:02:51.784484:  
2023-05-02 14:02:53.175775: Epoch 24 
2023-05-02 14:02:54.453445: Current learning rate: 0.00781 
2023-05-02 14:06:01.680562: train_loss -0.9611 
2023-05-02 14:06:03.220294: val_loss -0.854 
2023-05-02 14:06:05.414851: Pseudo dice [0.9224] 
2023-05-02 14:06:07.881763: Epoch time: 189.9 s 
2023-05-02 14:06:10.474370: Yayy! New best EMA pseudo Dice: 0.9229 
2023-05-02 14:06:23.184772:  
2023-05-02 14:06:24.383459: Epoch 25 
2023-05-02 14:06:25.779501: Current learning rate: 0.00772 
2023-05-02 14:08:44.099211: train_loss -0.9544 
2023-05-02 14:08:45.609484: val_loss -0.8582 
2023-05-02 14:08:46.914774: Pseudo dice [0.9204] 
2023-05-02 14:08:49.138692: Epoch time: 140.92 s 
2023-05-02 14:08:57.079566:  
2023-05-02 14:08:58.251728: Epoch 26 
2023-05-02 14:09:00.560627: Current learning rate: 0.00763 
2023-05-02 14:11:22.346591: train_loss -0.9587 
2023-05-02 14:11:23.830427: val_loss -0.8714 
2023-05-02 14:11:26.486077: Pseudo dice [0.9284] 
2023-05-02 14:11:28.756522: Epoch time: 145.27 s 
2023-05-02 14:11:31.212258: Yayy! New best EMA pseudo Dice: 0.9232 
2023-05-02 14:11:40.709066:  
2023-05-02 14:11:41.944844: Epoch 27 
2023-05-02 14:11:45.563384: Current learning rate: 0.00753 
2023-05-02 14:14:05.855632: train_loss -0.9623 
2023-05-02 14:14:07.322286: val_loss -0.8567 
2023-05-02 14:14:08.859770: Pseudo dice [0.9216] 
2023-05-02 14:14:10.394710: Epoch time: 145.15 s 
2023-05-02 14:14:16.765908:  
2023-05-02 14:14:18.071431: Epoch 28 
2023-05-02 14:14:20.719464: Current learning rate: 0.00744 
2023-05-02 14:16:45.927670: train_loss -0.9641 
2023-05-02 14:16:47.170885: val_loss -0.8758 
2023-05-02 14:16:49.897030: Pseudo dice [0.9313] 
2023-05-02 14:16:51.157480: Epoch time: 149.16 s 
2023-05-02 14:16:53.140199: Yayy! New best EMA pseudo Dice: 0.9239 
2023-05-02 14:17:04.022677:  
2023-05-02 14:17:06.087311: Epoch 29 
2023-05-02 14:17:09.948459: Current learning rate: 0.00735 
2023-05-02 14:19:39.477261: train_loss -0.9633 
2023-05-02 14:19:41.043631: val_loss -0.8491 
2023-05-02 14:19:42.285063: Pseudo dice [0.9173] 
2023-05-02 14:19:44.651916: Epoch time: 155.46 s 
2023-05-02 14:19:53.510921:  
2023-05-02 14:19:54.952447: Epoch 30 
2023-05-02 14:19:57.186912: Current learning rate: 0.00725 
2023-05-02 14:22:28.021993: train_loss -0.9622 
2023-05-02 14:22:29.650499: val_loss -0.8657 
2023-05-02 14:22:31.119498: Pseudo dice [0.9262] 
2023-05-02 14:22:33.506219: Epoch time: 154.51 s 
2023-05-02 14:22:39.251766:  
2023-05-02 14:22:40.811314: Epoch 31 
2023-05-02 14:22:42.897141: Current learning rate: 0.00716 
2023-05-02 14:25:15.114703: train_loss -0.9632 
2023-05-02 14:25:16.503277: val_loss -0.8641 
2023-05-02 14:25:18.429613: Pseudo dice [0.9254] 
2023-05-02 14:25:20.534540: Epoch time: 155.86 s 
2023-05-02 14:25:26.707295:  
2023-05-02 14:25:28.059377: Epoch 32 
2023-05-02 14:25:29.445372: Current learning rate: 0.00707 
2023-05-02 14:28:02.915503: train_loss -0.9654 
2023-05-02 14:28:04.226054: val_loss -0.8528 
2023-05-02 14:28:06.524540: Pseudo dice [0.9208] 
2023-05-02 14:28:09.256887: Epoch time: 156.21 s 
2023-05-02 14:28:14.895448:  
2023-05-02 14:28:16.779834: Epoch 33 
2023-05-02 14:28:18.091010: Current learning rate: 0.00697 
2023-05-02 14:30:49.299284: train_loss -0.9654 
2023-05-02 14:30:50.964283: val_loss -0.8826 
2023-05-02 14:30:53.218687: Pseudo dice [0.9346] 
2023-05-02 14:30:54.626543: Epoch time: 154.4 s 
2023-05-02 14:30:55.842849: Yayy! New best EMA pseudo Dice: 0.9245 
2023-05-02 14:31:06.736849:  
2023-05-02 14:31:08.003354: Epoch 34 
2023-05-02 14:31:10.479267: Current learning rate: 0.00688 
2023-05-02 14:33:41.868276: train_loss -0.9659 
2023-05-02 14:33:43.471349: val_loss -0.8774 
2023-05-02 14:33:44.691700: Pseudo dice [0.9332] 
2023-05-02 14:33:46.202663: Epoch time: 155.13 s 
2023-05-02 14:33:48.734700: Yayy! New best EMA pseudo Dice: 0.9254 
2023-05-02 14:34:00.062460:  
2023-05-02 14:34:01.506073: Epoch 35 
2023-05-02 14:34:02.945508: Current learning rate: 0.00679 
2023-05-02 14:36:35.086898: train_loss -0.9681 
2023-05-02 14:36:36.712752: val_loss -0.8561 
2023-05-02 14:36:39.076314: Pseudo dice [0.9228] 
2023-05-02 14:36:41.898324: Epoch time: 155.03 s 
2023-05-02 14:36:48.163085:  
2023-05-02 14:36:50.134623: Epoch 36 
2023-05-02 14:36:52.709848: Current learning rate: 0.00669 
2023-05-02 14:39:38.927057: train_loss -0.9685 
2023-05-02 14:39:40.223398: val_loss -0.8685 
2023-05-02 14:39:42.765062: Pseudo dice [0.9273] 
2023-05-02 14:39:45.454264: Epoch time: 170.77 s 
2023-05-02 14:39:50.488865:  
2023-05-02 14:39:51.761341: Epoch 37 
2023-05-02 14:39:53.319295: Current learning rate: 0.0066 
2023-05-02 14:42:22.273880: train_loss -0.964 
2023-05-02 14:42:23.436165: val_loss -0.8744 
2023-05-02 14:42:24.891501: Pseudo dice [0.9298] 
2023-05-02 14:42:27.529881: Epoch time: 151.79 s 
2023-05-02 14:42:29.779403: Yayy! New best EMA pseudo Dice: 0.9258 
2023-05-02 14:42:51.028360:  
2023-05-02 14:42:52.382071: Epoch 38 
2023-05-02 14:42:53.801159: Current learning rate: 0.0065 
2023-05-02 14:45:23.751302: train_loss -0.9662 
2023-05-02 14:45:25.149893: val_loss -0.866 
2023-05-02 14:45:27.789786: Pseudo dice [0.9273] 
2023-05-02 14:45:30.369801: Epoch time: 152.72 s 
2023-05-02 14:45:33.229558: Yayy! New best EMA pseudo Dice: 0.9259 
2023-05-02 14:45:42.806570:  
2023-05-02 14:45:44.211710: Epoch 39 
2023-05-02 14:45:46.802337: Current learning rate: 0.00641 
2023-05-02 14:48:16.475193: train_loss -0.9682 
2023-05-02 14:48:17.699851: val_loss -0.8782 
2023-05-02 14:48:20.359723: Pseudo dice [0.9336] 
2023-05-02 14:48:23.048598: Epoch time: 153.67 s 
2023-05-02 14:48:42.018920: Yayy! New best EMA pseudo Dice: 0.9267 
2023-05-02 14:48:52.140476:  
2023-05-02 14:48:53.540441: Epoch 40 
2023-05-02 14:48:56.316512: Current learning rate: 0.00631 
2023-05-02 14:51:26.382046: train_loss -0.9696 
2023-05-02 14:51:27.936977: val_loss -0.8403 
2023-05-02 14:51:30.650583: Pseudo dice [0.9112] 
2023-05-02 14:51:33.411464: Epoch time: 154.24 s 
2023-05-02 14:51:39.620533:  
2023-05-02 14:51:41.127861: Epoch 41 
2023-05-02 14:51:42.705817: Current learning rate: 0.00622 
2023-05-02 14:54:12.705187: train_loss -0.9707 
2023-05-02 14:54:14.185802: val_loss -0.878 
2023-05-02 14:54:16.565334: Pseudo dice [0.9351] 
2023-05-02 14:54:19.767733: Epoch time: 153.09 s 
2023-05-02 14:54:25.865767:  
2023-05-02 14:54:27.311302: Epoch 42 
2023-05-02 14:54:30.007819: Current learning rate: 0.00612 
2023-05-02 14:56:58.647591: train_loss -0.969 
2023-05-02 14:57:00.162197: val_loss -0.8463 
2023-05-02 14:57:01.400162: Pseudo dice [0.9146] 
2023-05-02 14:57:03.773348: Epoch time: 152.78 s 
2023-05-02 14:57:10.180095:  
2023-05-02 14:57:11.493225: Epoch 43 
2023-05-02 14:57:12.912732: Current learning rate: 0.00603 
2023-05-02 14:59:43.321415: train_loss -0.9691 
2023-05-02 14:59:44.783898: val_loss -0.8551 
2023-05-02 14:59:46.014989: Pseudo dice [0.9227] 
2023-05-02 14:59:49.435632: Epoch time: 153.14 s 
2023-05-02 14:59:55.074537:  
2023-05-02 14:59:56.470526: Epoch 44 
2023-05-02 14:59:59.143827: Current learning rate: 0.00593 
2023-05-02 15:02:31.157387: train_loss -0.9702 
2023-05-02 15:02:32.628691: val_loss -0.8567 
2023-05-02 15:02:35.251601: Pseudo dice [0.9219] 
2023-05-02 15:02:36.742543: Epoch time: 156.08 s 
2023-05-02 15:02:43.292168:  
2023-05-02 15:02:44.635865: Epoch 45 
2023-05-02 15:02:47.024653: Current learning rate: 0.00584 
2023-05-02 15:05:16.995661: train_loss -0.9723 
2023-05-02 15:05:18.395491: val_loss -0.8674 
2023-05-02 15:05:21.089642: Pseudo dice [0.9287] 
2023-05-02 15:05:23.839600: Epoch time: 153.7 s 
2023-05-02 15:05:31.922421:  
2023-05-02 15:05:33.391850: Epoch 46 
2023-05-02 15:05:36.055786: Current learning rate: 0.00574 
2023-05-02 15:08:05.829644: train_loss -0.9725 
2023-05-02 15:08:07.388919: val_loss -0.865 
2023-05-02 15:08:10.131856: Pseudo dice [0.9282] 
2023-05-02 15:08:12.407889: Epoch time: 153.91 s 
2023-05-02 15:08:19.067724:  
2023-05-02 15:08:20.695283: Epoch 47 
2023-05-02 15:08:22.847504: Current learning rate: 0.00565 
2023-05-02 15:10:56.176981: train_loss -0.9728 
2023-05-02 15:10:57.621995: val_loss -0.868 
2023-05-02 15:10:59.049777: Pseudo dice [0.9306] 
2023-05-02 15:11:00.431455: Epoch time: 157.11 s 
2023-05-02 15:11:05.941628:  
2023-05-02 15:11:07.373075: Epoch 48 
2023-05-02 15:11:09.907027: Current learning rate: 0.00555 
2023-05-02 15:13:43.912396: train_loss -0.9735 
2023-05-02 15:13:45.159642: val_loss -0.8581 
2023-05-02 15:13:47.458775: Pseudo dice [0.9239] 
2023-05-02 15:13:50.089734: Epoch time: 157.97 s 
2023-05-02 15:13:57.013150:  
2023-05-02 15:13:58.139835: Epoch 49 
2023-05-02 15:14:00.924914: Current learning rate: 0.00546 
2023-05-02 15:16:35.951311: train_loss -0.9737 
2023-05-02 15:16:37.344028: val_loss -0.8702 
2023-05-02 15:16:40.014354: Pseudo dice [0.9301] 
2023-05-02 15:16:42.266287: Epoch time: 158.94 s 
2023-05-02 15:16:51.501172:  
2023-05-02 15:16:52.853342: Epoch 50 
2023-05-02 15:16:57.120664: Current learning rate: 0.00536 
2023-05-02 15:19:32.427969: train_loss -0.9738 
2023-05-02 15:19:33.918184: val_loss -0.8664 
2023-05-02 15:19:36.304490: Pseudo dice [0.9298] 
2023-05-02 15:19:37.715939: Epoch time: 160.93 s 
2023-05-02 15:19:45.052850:  
2023-05-02 15:19:46.350880: Epoch 51 
2023-05-02 15:19:49.212056: Current learning rate: 0.00526 
2023-05-02 15:22:22.973127: train_loss -0.9741 
2023-05-02 15:22:24.405894: val_loss -0.8822 
2023-05-02 15:22:27.118334: Pseudo dice [0.9381] 
2023-05-02 15:22:29.146307: Epoch time: 157.92 s 
2023-05-02 15:22:30.589928: Yayy! New best EMA pseudo Dice: 0.9276 
2023-05-02 15:22:41.192708:  
2023-05-02 15:22:42.558293: Epoch 52 
2023-05-02 15:22:43.789597: Current learning rate: 0.00517 
2023-05-02 15:25:20.255904: train_loss -0.9739 
2023-05-02 15:25:21.741427: val_loss -0.8665 
2023-05-02 15:25:23.138575: Pseudo dice [0.9282] 
2023-05-02 15:25:24.661141: Epoch time: 159.06 s 
2023-05-02 15:25:27.404865: Yayy! New best EMA pseudo Dice: 0.9276 
2023-05-02 15:25:38.677418:  
2023-05-02 15:25:39.893559: Epoch 53 
2023-05-02 15:25:41.201083: Current learning rate: 0.00507 
2023-05-02 15:28:16.245107: train_loss -0.9752 
2023-05-02 15:28:17.765995: val_loss -0.8759 
2023-05-02 15:28:19.070651: Pseudo dice [0.9326] 
2023-05-02 15:28:20.511027: Epoch time: 157.57 s 
2023-05-02 15:28:23.214338: Yayy! New best EMA pseudo Dice: 0.9281 
2023-05-02 15:28:34.457325:  
2023-05-02 15:28:35.924294: Epoch 54 
2023-05-02 15:28:37.317793: Current learning rate: 0.00497 
2023-05-02 15:31:32.088182: train_loss -0.9753 
2023-05-02 15:31:33.579445: val_loss -0.8711 
2023-05-02 15:31:35.170542: Pseudo dice [0.9308] 
2023-05-02 15:31:36.668405: Epoch time: 177.63 s 
2023-05-02 15:31:39.107875: Yayy! New best EMA pseudo Dice: 0.9284 
2023-05-02 15:32:04.417509:  
2023-05-02 15:32:05.856771: Epoch 55 
2023-05-02 15:32:07.325440: Current learning rate: 0.00487 
2023-05-02 15:34:45.362723: train_loss -0.976 
2023-05-02 15:34:46.947135: val_loss -0.8619 
2023-05-02 15:34:49.449384: Pseudo dice [0.9253] 
2023-05-02 15:34:51.014812: Epoch time: 160.95 s 
2023-05-02 15:34:57.551025:  
2023-05-02 15:34:58.900109: Epoch 56 
2023-05-02 15:35:00.400663: Current learning rate: 0.00478 
2023-05-02 15:37:35.111517: train_loss -0.9755 
2023-05-02 15:37:36.405194: val_loss -0.8819 
2023-05-02 15:37:38.896273: Pseudo dice [0.9364] 
2023-05-02 15:37:40.778178: Epoch time: 157.56 s 
2023-05-02 15:37:42.985073: Yayy! New best EMA pseudo Dice: 0.9289 
2023-05-02 15:37:52.740577:  
2023-05-02 15:37:54.394118: Epoch 57 
2023-05-02 15:37:56.953993: Current learning rate: 0.00468 
2023-05-02 15:40:28.286079: train_loss -0.9761 
2023-05-02 15:40:29.942990: val_loss -0.8753 
2023-05-02 15:40:32.823594: Pseudo dice [0.9336] 
2023-05-02 15:40:35.507612: Epoch time: 155.55 s 
2023-05-02 15:40:38.099088: Yayy! New best EMA pseudo Dice: 0.9294 
2023-05-02 15:40:49.082119:  
2023-05-02 15:40:50.377343: Epoch 58 
2023-05-02 15:40:53.370651: Current learning rate: 0.00458 
2023-05-02 15:43:25.845544: train_loss -0.9761 
2023-05-02 15:43:27.275520: val_loss -0.8663 
2023-05-02 15:43:29.557845: Pseudo dice [0.9295] 
2023-05-02 15:43:32.214581: Epoch time: 156.76 s 
2023-05-02 15:43:33.545605: Yayy! New best EMA pseudo Dice: 0.9294 
2023-05-02 15:43:45.261031:  
2023-05-02 15:43:46.695183: Epoch 59 
2023-05-02 15:43:49.441568: Current learning rate: 0.00448 
2023-05-02 15:46:20.239331: train_loss -0.9764 
2023-05-02 15:46:21.698926: val_loss -0.8771 
2023-05-02 15:46:23.085031: Pseudo dice [0.936] 
2023-05-02 15:46:25.270473: Epoch time: 154.98 s 
2023-05-02 15:46:44.288885: Yayy! New best EMA pseudo Dice: 0.9301 
2023-05-02 15:46:53.913527:  
2023-05-02 15:46:55.431770: Epoch 60 
2023-05-02 15:46:57.773802: Current learning rate: 0.00438 
2023-05-02 15:49:28.660152: train_loss -0.9761 
2023-05-02 15:49:30.157960: val_loss -0.8836 
2023-05-02 15:49:32.820741: Pseudo dice [0.9373] 
2023-05-02 15:49:34.360574: Epoch time: 154.75 s 
2023-05-02 15:49:37.010586: Yayy! New best EMA pseudo Dice: 0.9308 
2023-05-02 15:49:46.751036:  
2023-05-02 15:49:48.122286: Epoch 61 
2023-05-02 15:49:50.939833: Current learning rate: 0.00429 
2023-05-02 15:52:20.877123: train_loss -0.9765 
2023-05-02 15:52:22.571041: val_loss -0.8745 
2023-05-02 15:52:23.932629: Pseudo dice [0.933] 
2023-05-02 15:52:26.693618: Epoch time: 154.13 s 
2023-05-02 15:52:28.268383: Yayy! New best EMA pseudo Dice: 0.931 
2023-05-02 15:52:40.749515:  
2023-05-02 15:52:42.278846: Epoch 62 
2023-05-02 15:52:43.843282: Current learning rate: 0.00419 
2023-05-02 15:55:19.119212: train_loss -0.9764 
2023-05-02 15:55:20.384280: val_loss -0.8703 
2023-05-02 15:55:21.832004: Pseudo dice [0.9293] 
2023-05-02 15:55:25.905341: Epoch time: 158.37 s 
2023-05-02 15:55:31.998770:  
2023-05-02 15:55:33.349264: Epoch 63 
2023-05-02 15:55:34.823576: Current learning rate: 0.00409 
2023-05-02 15:58:07.704885: train_loss -0.9768 
2023-05-02 15:58:08.897122: val_loss -0.8679 
2023-05-02 15:58:11.181268: Pseudo dice [0.9316] 
2023-05-02 15:58:12.477528: Epoch time: 155.71 s 
2023-05-02 15:58:20.151045:  
2023-05-02 15:58:21.763014: Epoch 64 
2023-05-02 15:58:23.060217: Current learning rate: 0.00399 
2023-05-02 16:00:54.295089: train_loss -0.9775 
2023-05-02 16:00:55.728690: val_loss -0.8825 
2023-05-02 16:00:58.424605: Pseudo dice [0.9382] 
2023-05-02 16:01:01.312882: Epoch time: 154.15 s 
2023-05-02 16:01:03.737458: Yayy! New best EMA pseudo Dice: 0.9317 
2023-05-02 16:01:14.728618:  
2023-05-02 16:01:16.059801: Epoch 65 
2023-05-02 16:01:18.322189: Current learning rate: 0.00389 
2023-05-02 16:03:50.452615: train_loss -0.9782 
2023-05-02 16:03:51.864649: val_loss -0.8814 
2023-05-02 16:03:54.622565: Pseudo dice [0.9377] 
2023-05-02 16:03:56.143936: Epoch time: 155.73 s 
2023-05-02 16:03:57.410877: Yayy! New best EMA pseudo Dice: 0.9323 
2023-05-02 16:04:08.718419:  
2023-05-02 16:04:10.262256: Epoch 66 
2023-05-02 16:04:11.753932: Current learning rate: 0.00379 
2023-05-02 16:06:45.688359: train_loss -0.9778 
2023-05-02 16:06:47.608102: val_loss -0.8836 
2023-05-02 16:06:49.295907: Pseudo dice [0.9389] 
2023-05-02 16:06:50.813907: Epoch time: 156.97 s 
2023-05-02 16:06:52.333819: Yayy! New best EMA pseudo Dice: 0.9329 
2023-05-02 16:07:04.788302:  
2023-05-02 16:07:06.274334: Epoch 67 
2023-05-02 16:07:08.635033: Current learning rate: 0.00369 
2023-05-02 16:09:42.824702: train_loss -0.9782 
2023-05-02 16:09:44.206984: val_loss -0.8804 
2023-05-02 16:09:46.113224: Pseudo dice [0.9378] 
2023-05-02 16:09:48.710370: Epoch time: 158.04 s 
2023-05-02 16:09:50.970798: Yayy! New best EMA pseudo Dice: 0.9334 
2023-05-02 16:10:02.235366:  
2023-05-02 16:10:03.858416: Epoch 68 
2023-05-02 16:10:05.103471: Current learning rate: 0.00359 
2023-05-02 16:12:37.878200: train_loss -0.9783 
2023-05-02 16:12:39.443508: val_loss -0.8782 
2023-05-02 16:12:40.835819: Pseudo dice [0.9356] 
2023-05-02 16:12:45.067046: Epoch time: 155.64 s 
2023-05-02 16:12:48.143140: Yayy! New best EMA pseudo Dice: 0.9336 
2023-05-02 16:12:58.712750:  
2023-05-02 16:13:00.004550: Epoch 69 
2023-05-02 16:13:02.346982: Current learning rate: 0.00349 
2023-05-02 16:15:35.597458: train_loss -0.9786 
2023-05-02 16:15:37.137321: val_loss -0.8747 
2023-05-02 16:15:40.003332: Pseudo dice [0.9339] 
2023-05-02 16:15:41.705637: Epoch time: 156.89 s 
2023-05-02 16:15:48.887591: Yayy! New best EMA pseudo Dice: 0.9336 
2023-05-02 16:15:59.862788:  
2023-05-02 16:16:01.151084: Epoch 70 
2023-05-02 16:16:02.665139: Current learning rate: 0.00338 
2023-05-02 16:18:40.026126: train_loss -0.9782 
2023-05-02 16:18:41.421742: val_loss -0.8769 
2023-05-02 16:18:44.006740: Pseudo dice [0.9359] 
2023-05-02 16:18:46.235343: Epoch time: 160.16 s 
2023-05-02 16:18:49.086490: Yayy! New best EMA pseudo Dice: 0.9339 
2023-05-02 16:19:02.061674:  
2023-05-02 16:19:03.374020: Epoch 71 
2023-05-02 16:19:05.656677: Current learning rate: 0.00328 
2023-05-02 16:21:37.295443: train_loss -0.9784 
2023-05-02 16:21:38.707365: val_loss -0.877 
2023-05-02 16:21:41.442326: Pseudo dice [0.9371] 
2023-05-02 16:21:42.747556: Epoch time: 155.23 s 
2023-05-02 16:21:45.212195: Yayy! New best EMA pseudo Dice: 0.9342 
2023-05-02 16:21:55.460924:  
2023-05-02 16:21:57.714313: Epoch 72 
2023-05-02 16:21:59.926737: Current learning rate: 0.00318 
2023-05-02 16:24:32.836701: train_loss -0.9783 
2023-05-02 16:24:34.425073: val_loss -0.8746 
2023-05-02 16:24:37.145775: Pseudo dice [0.9335] 
2023-05-02 16:24:38.550858: Epoch time: 157.38 s 
2023-05-02 16:24:44.504988:  
2023-05-02 16:24:45.789708: Epoch 73 
2023-05-02 16:24:48.211649: Current learning rate: 0.00308 
2023-05-02 16:27:17.735813: train_loss -0.9794 
2023-05-02 16:27:19.281005: val_loss -0.8756 
2023-05-02 16:27:20.599895: Pseudo dice [0.9357] 
2023-05-02 16:27:23.406268: Epoch time: 153.23 s 
2023-05-02 16:27:26.267395: Yayy! New best EMA pseudo Dice: 0.9343 
2023-05-02 16:27:36.867344:  
2023-05-02 16:27:38.065462: Epoch 74 
2023-05-02 16:27:40.125639: Current learning rate: 0.00297 
2023-05-02 16:30:15.760161: train_loss -0.9784 
2023-05-02 16:30:17.305611: val_loss -0.8707 
2023-05-02 16:30:18.685434: Pseudo dice [0.9331] 
2023-05-02 16:30:21.618912: Epoch time: 158.89 s 
2023-05-02 16:30:27.667574:  
2023-05-02 16:30:29.192633: Epoch 75 
2023-05-02 16:30:31.835256: Current learning rate: 0.00287 
2023-05-02 16:33:04.504374: train_loss -0.9793 
2023-05-02 16:33:06.000817: val_loss -0.876 
2023-05-02 16:33:08.669549: Pseudo dice [0.9358] 
2023-05-02 16:33:10.034739: Epoch time: 156.84 s 
2023-05-02 16:33:11.634819: Yayy! New best EMA pseudo Dice: 0.9343 
2023-05-02 16:33:22.622195:  
2023-05-02 16:33:24.094115: Epoch 76 
2023-05-02 16:33:25.732310: Current learning rate: 0.00277 
2023-05-02 16:35:59.813571: train_loss -0.9788 
2023-05-02 16:36:01.299819: val_loss -0.8782 
2023-05-02 16:36:02.813857: Pseudo dice [0.9364] 
2023-05-02 16:36:05.018902: Epoch time: 157.19 s 
2023-05-02 16:36:08.703674: Yayy! New best EMA pseudo Dice: 0.9345 
2023-05-02 16:36:17.570407:  
2023-05-02 16:36:18.934448: Epoch 77 
2023-05-02 16:36:21.060041: Current learning rate: 0.00266 
2023-05-02 16:38:51.992877: train_loss -0.9794 
2023-05-02 16:38:53.459331: val_loss -0.8755 
2023-05-02 16:38:54.976094: Pseudo dice [0.9361] 
2023-05-02 16:38:57.828611: Epoch time: 154.42 s 
2023-05-02 16:39:02.208085: Yayy! New best EMA pseudo Dice: 0.9347 
2023-05-02 16:39:11.689112:  
2023-05-02 16:39:13.264512: Epoch 78 
2023-05-02 16:39:16.173277: Current learning rate: 0.00256 
2023-05-02 16:41:49.725106: train_loss -0.9796 
2023-05-02 16:41:51.044373: val_loss -0.877 
2023-05-02 16:41:52.543417: Pseudo dice [0.9374] 
2023-05-02 16:41:54.862687: Epoch time: 158.04 s 
2023-05-02 16:41:57.091298: Yayy! New best EMA pseudo Dice: 0.935 
2023-05-02 16:42:08.519896:  
2023-05-02 16:42:10.277761: Epoch 79 
2023-05-02 16:42:11.543664: Current learning rate: 0.00245 
2023-05-02 16:44:42.022861: train_loss -0.9798 
2023-05-02 16:44:43.245421: val_loss -0.8708 
2023-05-02 16:44:45.390386: Pseudo dice [0.9338] 
2023-05-02 16:44:47.583447: Epoch time: 153.5 s 
2023-05-02 16:44:58.312864:  
2023-05-02 16:44:59.709163: Epoch 80 
2023-05-02 16:45:02.315508: Current learning rate: 0.00235 
2023-05-02 16:47:30.672336: train_loss -0.9799 
2023-05-02 16:47:32.146054: val_loss -0.8757 
2023-05-02 16:47:34.691424: Pseudo dice [0.9376] 
2023-05-02 16:47:37.278928: Epoch time: 152.36 s 
2023-05-02 16:47:39.999745: Yayy! New best EMA pseudo Dice: 0.9351 
2023-05-02 16:47:50.515896:  
2023-05-02 16:47:51.845051: Epoch 81 
2023-05-02 16:47:54.608660: Current learning rate: 0.00224 
2023-05-02 16:50:27.332679: train_loss -0.9797 
2023-05-02 16:50:28.783546: val_loss -0.8737 
2023-05-02 16:50:30.271350: Pseudo dice [0.9347] 
2023-05-02 16:50:31.538929: Epoch time: 156.82 s 
2023-05-02 16:50:38.004385:  
2023-05-02 16:50:39.426516: Epoch 82 
2023-05-02 16:50:40.926278: Current learning rate: 0.00214 
2023-05-02 16:53:11.900699: train_loss -0.9798 
2023-05-02 16:53:13.198213: val_loss -0.8747 
2023-05-02 16:53:15.825102: Pseudo dice [0.9359] 
2023-05-02 16:53:17.355994: Epoch time: 153.9 s 
2023-05-02 16:53:18.941668: Yayy! New best EMA pseudo Dice: 0.9352 
2023-05-02 16:53:30.293842:  
2023-05-02 16:53:31.880386: Epoch 83 
2023-05-02 16:53:35.695589: Current learning rate: 0.00203 
2023-05-02 16:56:07.725129: train_loss -0.98 
2023-05-02 16:56:09.628868: val_loss -0.8732 
2023-05-02 16:56:12.739455: Pseudo dice [0.934] 
2023-05-02 16:56:15.460131: Epoch time: 157.43 s 
2023-05-02 16:56:21.350086:  
2023-05-02 16:56:22.845565: Epoch 84 
2023-05-02 16:56:25.292125: Current learning rate: 0.00192 
2023-05-02 16:58:54.891599: train_loss -0.9802 
2023-05-02 16:58:56.480615: val_loss -0.8782 
2023-05-02 16:58:59.153559: Pseudo dice [0.9367] 
2023-05-02 16:59:00.541608: Epoch time: 153.54 s 
2023-05-02 16:59:03.203107: Yayy! New best EMA pseudo Dice: 0.9352 
2023-05-02 16:59:13.678477:  
2023-05-02 16:59:15.137464: Epoch 85 
2023-05-02 16:59:16.486444: Current learning rate: 0.00181 
2023-05-02 17:01:50.190359: train_loss -0.98 
2023-05-02 17:01:51.848609: val_loss -0.8814 
2023-05-02 17:01:54.713548: Pseudo dice [0.9391] 
2023-05-02 17:01:57.660923: Epoch time: 156.51 s 
2023-05-02 17:01:58.912583: Yayy! New best EMA pseudo Dice: 0.9356 
2023-05-02 17:02:10.279766:  
2023-05-02 17:02:11.654624: Epoch 86 
2023-05-02 17:02:16.644954: Current learning rate: 0.0017 
2023-05-02 17:04:45.756115: train_loss -0.9799 
2023-05-02 17:04:46.993098: val_loss -0.8759 
2023-05-02 17:04:48.295215: Pseudo dice [0.9363] 
2023-05-02 17:04:50.456448: Epoch time: 155.48 s 
2023-05-02 17:04:53.523192: Yayy! New best EMA pseudo Dice: 0.9357 
2023-05-02 17:05:05.501616:  
2023-05-02 17:05:06.801936: Epoch 87 
2023-05-02 17:05:09.500127: Current learning rate: 0.00159 
2023-05-02 17:07:38.918962: train_loss -0.9804 
2023-05-02 17:07:40.504646: val_loss -0.8705 
2023-05-02 17:07:41.933749: Pseudo dice [0.9339] 
2023-05-02 17:07:45.331640: Epoch time: 153.42 s 
2023-05-02 17:07:52.036808:  
2023-05-02 17:07:53.755022: Epoch 88 
2023-05-02 17:07:56.277798: Current learning rate: 0.00148 
2023-05-02 17:10:26.585801: train_loss -0.9803 
2023-05-02 17:10:28.296924: val_loss -0.8726 
2023-05-02 17:10:30.980106: Pseudo dice [0.9343] 
2023-05-02 17:10:32.620844: Epoch time: 154.55 s 
2023-05-02 17:10:37.712998:  
2023-05-02 17:10:39.118613: Epoch 89 
2023-05-02 17:10:41.941768: Current learning rate: 0.00137 
2023-05-02 17:13:17.081016: train_loss -0.9803 
2023-05-02 17:13:18.763134: val_loss -0.8738 
2023-05-02 17:13:21.417668: Pseudo dice [0.9347] 
2023-05-02 17:13:24.048325: Epoch time: 159.37 s 
2023-05-02 17:13:35.283861:  
2023-05-02 17:13:36.750571: Epoch 90 
2023-05-02 17:13:38.125924: Current learning rate: 0.00126 
2023-05-02 17:16:11.367045: train_loss -0.9806 
2023-05-02 17:16:12.936896: val_loss -0.8742 
2023-05-02 17:16:15.187063: Pseudo dice [0.9342] 
2023-05-02 17:16:17.518609: Epoch time: 156.08 s 
2023-05-02 17:16:23.652715:  
2023-05-02 17:16:25.037701: Epoch 91 
2023-05-02 17:16:26.265415: Current learning rate: 0.00115 
2023-05-02 17:18:56.840206: train_loss -0.9808 
2023-05-02 17:18:58.451584: val_loss -0.8744 
2023-05-02 17:18:59.784162: Pseudo dice [0.9355] 
2023-05-02 17:19:02.139391: Epoch time: 153.19 s 
2023-05-02 17:19:06.925749:  
2023-05-02 17:19:08.365779: Epoch 92 
2023-05-02 17:19:09.923462: Current learning rate: 0.00103 
2023-05-02 17:21:39.679612: train_loss -0.9812 
2023-05-02 17:21:41.365564: val_loss -0.8736 
2023-05-02 17:21:44.297682: Pseudo dice [0.9366] 
2023-05-02 17:21:45.586066: Epoch time: 152.75 s 
2023-05-02 17:21:51.830981:  
2023-05-02 17:21:53.284368: Epoch 93 
2023-05-02 17:21:57.012563: Current learning rate: 0.00091 
2023-05-02 17:24:29.955688: train_loss -0.9809 
2023-05-02 17:24:31.431932: val_loss -0.8712 
2023-05-02 17:24:31.436674: Pseudo dice [0.934] 
2023-05-02 17:24:32.948365: Epoch time: 158.13 s 
2023-05-02 17:24:38.137699:  
2023-05-02 17:24:39.341858: Epoch 94 
2023-05-02 17:24:41.896034: Current learning rate: 0.00079 
2023-05-02 17:27:16.654883: train_loss -0.9811 
2023-05-02 17:27:18.198843: val_loss -0.8785 
2023-05-02 17:27:21.109747: Pseudo dice [0.9372] 
2023-05-02 17:27:23.710607: Epoch time: 158.52 s 
2023-05-02 17:27:30.379173:  
2023-05-02 17:27:31.761658: Epoch 95 
2023-05-02 17:27:33.162919: Current learning rate: 0.00067 
2023-05-02 17:30:06.391915: train_loss -0.981 
2023-05-02 17:30:07.926954: val_loss -0.8763 
2023-05-02 17:30:10.265003: Pseudo dice [0.9358] 
2023-05-02 17:30:12.838781: Epoch time: 156.01 s 
2023-05-02 17:30:19.972755:  
2023-05-02 17:30:21.523273: Epoch 96 
2023-05-02 17:30:24.045389: Current learning rate: 0.00055 
2023-05-02 17:32:57.167563: train_loss -0.9806 
2023-05-02 17:32:58.745286: val_loss -0.8791 
2023-05-02 17:33:01.691581: Pseudo dice [0.9381] 
2023-05-02 17:33:04.654714: Epoch time: 157.2 s 
2023-05-02 17:33:07.065664: Yayy! New best EMA pseudo Dice: 0.9357 
2023-05-02 17:33:18.448871:  
2023-05-02 17:33:19.910327: Epoch 97 
2023-05-02 17:33:21.327056: Current learning rate: 0.00043 
2023-05-02 17:35:53.451093: train_loss -0.9805 
2023-05-02 17:35:54.976053: val_loss -0.8797 
2023-05-02 17:35:57.321565: Pseudo dice [0.9387] 
2023-05-02 17:35:59.950329: Epoch time: 155.0 s 
2023-05-02 17:36:01.427635: Yayy! New best EMA pseudo Dice: 0.936 
2023-05-02 17:36:10.999026:  
2023-05-02 17:36:12.507102: Epoch 98 
2023-05-02 17:36:15.170862: Current learning rate: 0.0003 
2023-05-02 17:38:49.599027: train_loss -0.9814 
2023-05-02 17:38:50.997044: val_loss -0.8777 
2023-05-02 17:38:53.712824: Pseudo dice [0.9373] 
2023-05-02 17:38:55.204360: Epoch time: 158.6 s 
2023-05-02 17:38:58.385698: Yayy! New best EMA pseudo Dice: 0.9361 
2023-05-02 17:39:09.381692:  
2023-05-02 17:39:10.850624: Epoch 99 
2023-05-02 17:39:13.772993: Current learning rate: 0.00016 
