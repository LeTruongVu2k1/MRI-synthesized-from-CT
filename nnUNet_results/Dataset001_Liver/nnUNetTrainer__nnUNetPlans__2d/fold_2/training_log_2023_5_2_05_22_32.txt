
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 23, 'patch_size': [256, 192], 'median_image_size_in_voxels': [251.5, 186.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Liver', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [30, 252, 186], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0, 'mean': 0.2606104910373688, 'median': 0.24769647419452667, 'min': 0.0, 'percentile_00_5': 0.06384892016649246, 'percentile_99_5': 0.6531020402908325, 'std': 0.0987810268998146}}} 
 
2023-05-02 05:22:35.693827: unpacking dataset... 
2023-05-02 05:22:35.946564: unpacking done... 
2023-05-02 05:22:35.948956: do_dummy_2d_data_aug: False 
2023-05-02 05:22:35.956259: Using splits from existing split file: drive/MyDrive/nnUNet/nnUNet_preprocessed/Dataset001_Liver/splits_final.json 
2023-05-02 05:22:35.959810: The split file contains 5 splits. 
2023-05-02 05:22:35.961803: Desired fold for training: 2 
2023-05-02 05:22:35.965537: This split has 13 training and 3 validation cases. 
2023-05-02 05:22:36.001419: Unable to plot network architecture: 
2023-05-02 05:22:36.003198: No module named 'hiddenlayer' 
2023-05-02 05:22:36.014602:  
2023-05-02 05:22:36.016521: Epoch 0 
2023-05-02 05:22:36.019953: Current learning rate: 0.01 
2023-05-02 05:25:13.449932: train_loss -0.4751 
2023-05-02 05:25:13.453802: val_loss -0.7324 
2023-05-02 05:25:13.457964: Pseudo dice [0.8384] 
2023-05-02 05:25:13.461398: Epoch time: 157.44 s 
2023-05-02 05:25:13.467099: Yayy! New best EMA pseudo Dice: 0.8384 
2023-05-02 05:25:16.817198:  
2023-05-02 05:25:16.820041: Epoch 1 
2023-05-02 05:25:16.822847: Current learning rate: 0.00964 
2023-05-02 05:27:47.410443: train_loss -0.8048 
2023-05-02 05:27:47.414053: val_loss -0.7921 
2023-05-02 05:27:47.418166: Pseudo dice [0.8751] 
2023-05-02 05:27:47.422035: Epoch time: 150.6 s 
2023-05-02 05:27:47.427373: Yayy! New best EMA pseudo Dice: 0.8421 
2023-05-02 05:27:50.776800:  
2023-05-02 05:27:50.779180: Epoch 2 
2023-05-02 05:27:50.782429: Current learning rate: 0.00928 
2023-05-02 05:30:20.619843: train_loss -0.8716 
2023-05-02 05:30:20.624810: val_loss -0.8177 
2023-05-02 05:30:20.629971: Pseudo dice [0.8931] 
2023-05-02 05:30:20.634014: Epoch time: 149.84 s 
2023-05-02 05:30:21.361161: Yayy! New best EMA pseudo Dice: 0.8472 
2023-05-02 05:30:24.527422:  
2023-05-02 05:30:24.531111: Epoch 3 
2023-05-02 05:30:24.534344: Current learning rate: 0.00891 
2023-05-02 05:32:51.804361: train_loss -0.9029 
2023-05-02 05:32:51.808602: val_loss -0.7941 
2023-05-02 05:32:51.812456: Pseudo dice [0.8782] 
2023-05-02 05:32:51.817429: Epoch time: 147.28 s 
2023-05-02 05:32:51.821517: Yayy! New best EMA pseudo Dice: 0.8503 
2023-05-02 05:32:55.298561:  
2023-05-02 05:32:55.300896: Epoch 4 
2023-05-02 05:32:55.303724: Current learning rate: 0.00855 
2023-05-02 05:35:24.573545: train_loss -0.9128 
2023-05-02 05:35:24.580231: val_loss -0.7956 
2023-05-02 05:35:24.584343: Pseudo dice [0.8788] 
2023-05-02 05:35:24.588201: Epoch time: 149.28 s 
2023-05-02 05:35:24.591727: Yayy! New best EMA pseudo Dice: 0.8531 
2023-05-02 05:35:27.875618:  
2023-05-02 05:35:27.878081: Epoch 5 
2023-05-02 05:35:27.881098: Current learning rate: 0.00818 
2023-05-02 05:37:57.357671: train_loss -0.9228 
2023-05-02 05:37:57.361718: val_loss -0.8028 
2023-05-02 05:37:57.365029: Pseudo dice [0.8875] 
2023-05-02 05:37:57.369589: Epoch time: 149.48 s 
2023-05-02 05:37:58.068368: Yayy! New best EMA pseudo Dice: 0.8566 
2023-05-02 05:38:01.113208:  
2023-05-02 05:38:01.115530: Epoch 6 
2023-05-02 05:38:01.118677: Current learning rate: 0.00781 
2023-05-02 05:49:33.999673: train_loss -0.9289 
2023-05-02 05:49:34.003747: val_loss -0.8626 
2023-05-02 05:49:34.007203: Pseudo dice [0.9169] 
2023-05-02 05:49:34.011475: Epoch time: 692.89 s 
2023-05-02 05:49:34.015026: Yayy! New best EMA pseudo Dice: 0.8626 
2023-05-02 05:49:37.489372:  
2023-05-02 05:49:37.491680: Epoch 7 
2023-05-02 05:49:37.494595: Current learning rate: 0.00744 
2023-05-02 05:52:04.291014: train_loss -0.9367 
2023-05-02 05:52:04.295605: val_loss -0.8417 
2023-05-02 05:52:04.299268: Pseudo dice [0.9055] 
2023-05-02 05:52:04.302607: Epoch time: 146.8 s 
2023-05-02 05:52:04.306432: Yayy! New best EMA pseudo Dice: 0.8669 
2023-05-02 05:52:07.650793:  
2023-05-02 05:52:07.653035: Epoch 8 
2023-05-02 05:52:07.656137: Current learning rate: 0.00707 
2023-05-02 05:54:34.721435: train_loss -0.9407 
2023-05-02 05:54:34.725519: val_loss -0.8336 
2023-05-02 05:54:34.729985: Pseudo dice [0.9011] 
2023-05-02 05:54:34.733958: Epoch time: 147.07 s 
2023-05-02 05:54:35.457100: Yayy! New best EMA pseudo Dice: 0.8703 
2023-05-02 05:54:38.815332:  
2023-05-02 05:54:38.817506: Epoch 9 
2023-05-02 05:54:38.820306: Current learning rate: 0.00669 
2023-05-02 05:57:04.866363: train_loss -0.9455 
2023-05-02 05:57:04.870364: val_loss -0.8611 
2023-05-02 05:57:04.875953: Pseudo dice [0.9193] 
2023-05-02 05:57:04.880135: Epoch time: 146.05 s 
2023-05-02 05:57:04.883502: Yayy! New best EMA pseudo Dice: 0.8752 
2023-05-02 05:57:08.245131:  
2023-05-02 05:57:08.247570: Epoch 10 
2023-05-02 05:57:08.250695: Current learning rate: 0.00631 
2023-05-02 05:59:36.470831: train_loss -0.9482 
2023-05-02 05:59:36.475157: val_loss -0.8224 
2023-05-02 05:59:36.479095: Pseudo dice [0.8946] 
2023-05-02 05:59:36.484712: Epoch time: 148.23 s 
2023-05-02 05:59:36.490465: Yayy! New best EMA pseudo Dice: 0.8771 
2023-05-02 05:59:39.777852:  
2023-05-02 05:59:39.780103: Epoch 11 
2023-05-02 05:59:39.783216: Current learning rate: 0.00593 
2023-05-02 06:02:08.187103: train_loss -0.9496 
2023-05-02 06:02:08.194309: val_loss -0.8623 
2023-05-02 06:02:08.199473: Pseudo dice [0.9206] 
2023-05-02 06:02:08.204240: Epoch time: 148.41 s 
2023-05-02 06:02:09.377348: Yayy! New best EMA pseudo Dice: 0.8815 
2023-05-02 06:02:14.055108:  
2023-05-02 06:02:14.057663: Epoch 12 
2023-05-02 06:02:14.060663: Current learning rate: 0.00555 
2023-05-02 06:04:49.011116: train_loss -0.9524 
2023-05-02 06:04:49.024078: val_loss -0.8335 
2023-05-02 06:04:49.028631: Pseudo dice [0.9081] 
2023-05-02 06:04:49.034167: Epoch time: 154.96 s 
2023-05-02 06:04:49.038842: Yayy! New best EMA pseudo Dice: 0.8842 
2023-05-02 06:04:52.940932:  
2023-05-02 06:04:52.943831: Epoch 13 
2023-05-02 06:04:52.947331: Current learning rate: 0.00517 
2023-05-02 06:07:28.998909: train_loss -0.9535 
2023-05-02 06:07:29.003204: val_loss -0.8418 
2023-05-02 06:07:29.007518: Pseudo dice [0.9072] 
2023-05-02 06:07:29.012399: Epoch time: 156.06 s 
2023-05-02 06:07:29.018365: Yayy! New best EMA pseudo Dice: 0.8865 
2023-05-02 06:07:32.424193:  
2023-05-02 06:07:32.427423: Epoch 14 
2023-05-02 06:07:32.430493: Current learning rate: 0.00478 
2023-05-02 06:09:58.525553: train_loss -0.9563 
2023-05-02 06:09:58.530620: val_loss -0.8575 
2023-05-02 06:09:58.534101: Pseudo dice [0.9191] 
2023-05-02 06:09:58.548567: Epoch time: 146.1 s 
2023-05-02 06:09:59.517804: Yayy! New best EMA pseudo Dice: 0.8897 
2023-05-02 06:10:03.069183:  
2023-05-02 06:10:03.071450: Epoch 15 
2023-05-02 06:10:03.074495: Current learning rate: 0.00438 
2023-05-02 06:12:34.559305: train_loss -0.9576 
2023-05-02 06:12:34.563562: val_loss -0.8496 
2023-05-02 06:12:34.567911: Pseudo dice [0.9161] 
2023-05-02 06:12:34.572503: Epoch time: 151.49 s 
2023-05-02 06:12:34.576600: Yayy! New best EMA pseudo Dice: 0.8924 
2023-05-02 06:12:38.028222:  
2023-05-02 06:12:38.040308: Epoch 16 
2023-05-02 06:12:38.042983: Current learning rate: 0.00399 
2023-05-02 06:15:07.844670: train_loss -0.9586 
2023-05-02 06:15:07.849762: val_loss -0.8605 
2023-05-02 06:15:07.853389: Pseudo dice [0.9224] 
2023-05-02 06:15:07.864456: Epoch time: 149.82 s 
2023-05-02 06:15:07.870085: Yayy! New best EMA pseudo Dice: 0.8954 
2023-05-02 06:15:11.268407:  
2023-05-02 06:15:11.270849: Epoch 17 
2023-05-02 06:15:11.273912: Current learning rate: 0.00359 
2023-05-02 06:17:39.165479: train_loss -0.9602 
2023-05-02 06:17:39.172375: val_loss -0.8512 
2023-05-02 06:17:39.176870: Pseudo dice [0.917] 
2023-05-02 06:17:39.181483: Epoch time: 147.9 s 
2023-05-02 06:17:39.931078: Yayy! New best EMA pseudo Dice: 0.8975 
2023-05-02 06:17:43.171423:  
2023-05-02 06:17:43.173845: Epoch 18 
2023-05-02 06:17:43.176914: Current learning rate: 0.00318 
2023-05-02 06:20:10.042012: train_loss -0.9611 
2023-05-02 06:20:10.046099: val_loss -0.846 
2023-05-02 06:20:10.050037: Pseudo dice [0.9136] 
2023-05-02 06:20:10.054030: Epoch time: 146.87 s 
2023-05-02 06:20:10.068391: Yayy! New best EMA pseudo Dice: 0.8991 
2023-05-02 06:20:13.488370:  
2023-05-02 06:20:13.490601: Epoch 19 
2023-05-02 06:20:13.493599: Current learning rate: 0.00277 
2023-05-02 06:22:39.148906: train_loss -0.9608 
2023-05-02 06:22:39.154879: val_loss -0.8653 
2023-05-02 06:22:39.161231: Pseudo dice [0.9249] 
2023-05-02 06:22:39.166354: Epoch time: 145.66 s 
2023-05-02 06:22:39.171416: Yayy! New best EMA pseudo Dice: 0.9017 
2023-05-02 06:22:43.326385:  
2023-05-02 06:22:43.328718: Epoch 20 
2023-05-02 06:22:43.331649: Current learning rate: 0.00235 
2023-05-02 06:25:07.564345: train_loss -0.9624 
2023-05-02 06:25:07.569134: val_loss -0.8629 
2023-05-02 06:25:07.573595: Pseudo dice [0.9214] 
2023-05-02 06:25:07.577870: Epoch time: 144.24 s 
2023-05-02 06:25:08.351100: Yayy! New best EMA pseudo Dice: 0.9037 
2023-05-02 06:25:11.807246:  
2023-05-02 06:25:11.809812: Epoch 21 
2023-05-02 06:25:11.812672: Current learning rate: 0.00192 
2023-05-02 06:27:37.473009: train_loss -0.9636 
2023-05-02 06:27:37.477952: val_loss -0.8619 
2023-05-02 06:27:37.483055: Pseudo dice [0.9218] 
2023-05-02 06:27:37.486715: Epoch time: 145.67 s 
2023-05-02 06:27:37.491124: Yayy! New best EMA pseudo Dice: 0.9055 
2023-05-02 06:27:41.178651:  
2023-05-02 06:27:41.181778: Epoch 22 
2023-05-02 06:27:41.184328: Current learning rate: 0.00148 
2023-05-02 06:30:03.911504: train_loss -0.9639 
2023-05-02 06:30:03.921983: val_loss -0.8498 
2023-05-02 06:30:03.927101: Pseudo dice [0.9162] 
2023-05-02 06:30:03.930927: Epoch time: 142.73 s 
2023-05-02 06:30:03.937190: Yayy! New best EMA pseudo Dice: 0.9066 
2023-05-02 06:30:08.904653:  
2023-05-02 06:30:08.906879: Epoch 23 
2023-05-02 06:30:08.910017: Current learning rate: 0.00103 
2023-05-02 06:32:32.941253: train_loss -0.9647 
2023-05-02 06:32:32.944662: val_loss -0.852 
2023-05-02 06:32:32.949527: Pseudo dice [0.9186] 
2023-05-02 06:32:32.953135: Epoch time: 144.04 s 
2023-05-02 06:32:33.660200: Yayy! New best EMA pseudo Dice: 0.9078 
2023-05-02 06:32:36.759450:  
2023-05-02 06:32:36.761712: Epoch 24 
2023-05-02 06:32:36.764918: Current learning rate: 0.00055 
2023-05-02 06:34:59.547194: train_loss -0.9646 
2023-05-02 06:34:59.552384: val_loss -0.8388 
2023-05-02 06:34:59.556112: Pseudo dice [0.9126] 
2023-05-02 06:34:59.559144: Epoch time: 142.79 s 
2023-05-02 06:34:59.562162: Yayy! New best EMA pseudo Dice: 0.9083 
2023-05-02 06:35:03.419508: Training done. 
2023-05-02 06:35:03.532014: Using splits from existing split file: drive/MyDrive/nnUNet/nnUNet_preprocessed/Dataset001_Liver/splits_final.json 
2023-05-02 06:35:03.536843: The split file contains 5 splits. 
2023-05-02 06:35:03.541654: Desired fold for training: 2 
2023-05-02 06:35:03.547023: This split has 13 training and 3 validation cases. 
2023-05-02 06:35:03.552879: predicting 34 
2023-05-02 06:35:05.142133: predicting 5 
2023-05-02 06:35:07.088756: predicting 8 
2023-05-02 06:35:27.907711: Validation complete 
2023-05-02 06:35:27.910836: Mean Validation Dice:  0.9130575553044621 
